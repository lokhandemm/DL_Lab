{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**DL PRACTICAL NO: 1**"
      ],
      "metadata": {
        "id": "wTussukJy0RT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Name: Maithili Lokhande\n",
        "\n",
        "#Batch: B1\n",
        "\n",
        "#Roll No: 7"
      ],
      "metadata": {
        "id": "mycG046Ey7Nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AIM:**\n",
        "\n",
        "1: Implement a single-layer perceptron model in Python to classify binary inputs using a step activation function. Test its performance on a simple binary classification problem.\n",
        "\n",
        "2: Utilize the single perceptron to simulate basic logic gates (AND, OR, NOT). Design the perceptron architecture to classify inputs based on predefined threshold values.\n",
        "\n",
        "3: Extend the perceptron implementation to simulate complex logic gates (NAND, NOR, XOR, XNOR). Validate the outputs using different combinations of binary inputs."
      ],
      "metadata": {
        "id": "T81lfyEHzKv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Implementing a Single-Layer Perceptron Model for Binary Classification"
      ],
      "metadata": {
        "id": "MLf9ttnmztw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "# Step activation fn\n",
        "def step_function(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "# Perceptron\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size):\n",
        "        self.weights=np.random.randn(input_size)\n",
        "        self.bias=np.random.randn()\n",
        "    def predict(self,x):\n",
        "        return step_function(np.dot(self.weights,x)+self.bias)\n",
        "    def train(self,X,y,epochs=10,lr=0.1):\n",
        "        for _ in range(epochs):\n",
        "            for xi,target in zip(X,y):\n",
        "                pred=self.predict(xi)\n",
        "                error=target-pred\n",
        "                self.weights+= lr*error*xi\n",
        "                self.bias +=lr*error\n",
        "# Binary Classification(and)\n",
        "X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y=np.array([0,0,0,1])\n",
        "perceptron =Perceptron(input_size=2)\n",
        "perceptron.train(X,y)\n",
        "print(\"Binary Classification Output:\",[perceptron.predict(x) for x in X])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdIXV11rqit_",
        "outputId": "d55a8a33-e5b2-40f7-bcbe-a807d87bfea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Classification Output: [0, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Simulating Basic Logic Gates (AND, OR, NOT)"
      ],
      "metadata": {
        "id": "B5KsTjM7z1Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y=np.array([0,0,0,1])\n",
        "perceptron=Perceptron(input_size=2)\n",
        "perceptron.train(X,y)\n",
        "print(\"AND Gate Output:\",[perceptron.predict(x) for x in X])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtUkDXhxtqpO",
        "outputId": "c60ed3ef-1b5b-443e-d08e-a7e71c84fa9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Gate Output: [0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array([0,1,1,1])\n",
        "perceptron =Perceptron(input_size=2)\n",
        "perceptron.train(X,y)\n",
        "print(\"OR Gate Output:\",[perceptron.predict(x) for x in X])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-3rwU1_tsxD",
        "outputId": "66563229-94ed-43b3-e3e1-a2f2926988d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR Gate Output: [1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array([[0],[1]])\n",
        "y=np.array([1, 0])\n",
        "perceptron= Perceptron(input_size=1)\n",
        "perceptron.train(X, y)\n",
        "print(\"NOT Gate Output:\", [perceptron.predict(x) for x in X])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfQXPYxitvJ1",
        "outputId": "20aae4e3-bcd8-42f3-914d-a2dad8b0d41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT Gate Output: [1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Simulating Complex Logic Gates (NAND, NOR, XOR, XNOR)"
      ],
      "metadata": {
        "id": "gmzHKv56z3PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NAND Gate Training\n",
        "X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y=np.array([1,1,1,0])\n",
        "perceptron = Perceptron(input_size=2)\n",
        "perceptron.train(X, y, epochs=50, lr=0.1)\n",
        "print(\"NAND Gate Output:\", [perceptron.predict(x) for x in X])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t45VMRJAtxzE",
        "outputId": "e005cbae-74fc-4175-e148-40dd319d93ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAND Gate Output: [1, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y=np.array([1,0,0,0])\n",
        "perceptron=Perceptron(input_size=2)\n",
        "perceptron.train(X, y)\n",
        "print(\"NOR Gate Output:\", [perceptron.predict(x) for x in X])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4zNUnXct2O3",
        "outputId": "04cf3548-3627-4345-a28b-f06a3c98f195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOR Gate Output: [1, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XOR using MLP:\n",
        "def train_mlp(X,y):\n",
        "    np.random.seed(42)\n",
        "    w1,w2=np.random.rand(2,2),np.random.rand(2,1)\n",
        "    b1,b2=np.random.rand(1,2),np.random.rand(1,1)\n",
        "    def sigmoid(x):\n",
        "      return 1/(1 + np.exp(-x))\n",
        "    def sigmoid_derivative(x):\n",
        "      return x*(1-x)\n",
        "    for _ in range(10000):\n",
        "        h=sigmoid(X @ w1+b1)\n",
        "        o=sigmoid(h @ w2+b2)\n",
        "        o_error=y-o\n",
        "        w2+=h.T @ (o_error* sigmoid_derivative(o))*0.1\n",
        "        b2 +=np.sum(o_error* sigmoid_derivative(o),axis=0,keepdims=True)*0.1\n",
        "        h_error= (o_error *sigmoid_derivative(o))@ w2.T\n",
        "        w1+=X.T @ (h_error*sigmoid_derivative(h))*0.1\n",
        "        b1+=np.sum(h_error*sigmoid_derivative(h),axis=0,keepdims=True)*0.1\n",
        "    return np.round(sigmoid(sigmoid(X @ w1 + b1)@ w2 + b2)).flatten()\n",
        "# Xor\n",
        "y_xor=np.array([[0],[1],[1],[0]])\n",
        "xor_output=train_mlp(X,y_xor)\n",
        "print(\"XOR Output:  \",xor_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwECA6eowGSs",
        "outputId": "a08712ca-5a5a-414b-e94c-d0586741b135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR Output:   [0. 1. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Xnor\n",
        "y_xnor = np.array([[1],[0],[0],[1]])\n",
        "xnor_output = train_mlp(X,y_xnor)\n",
        "print(\"XNOR Output:\",xnor_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV-uSsTjw6Dw",
        "outputId": "84dee32c-ca61-4958-892b-a5cedc9a3e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XNOR Output: [1. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CONCLUSION:**"
      ],
      "metadata": {
        "id": "LPzvadTQziGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#In this practical, we implemented a single-layer perceptron to classify binary inputs and simulate basic logic gates like AND. However, since XOR and XNOR are non-linearly separable, a multi-layer perceptron (MLP) was used to achieve correct results. This demonstrates the limitations of single-layer perceptrons and the need for multi-layer networks in solving complex classification problems."
      ],
      "metadata": {
        "id": "qqVdaYJ1zgex"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kOHEVE3bzhBU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}